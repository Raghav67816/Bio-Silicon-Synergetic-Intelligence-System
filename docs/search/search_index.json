{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"Bio-Silicon Synergetic Intelligence System"},{"location":"#project-overview","title":"\ud83e\udde0 Project Overview","text":"<p>At Synthetic Intelligence Labs, our mission is to harmonize biological cognition with computational rigor. We have embarked on an innovative venture that intricately fuses human cortical organoids with rat brains, unveiling a new era of bio-silicon synergetic learning. Our bespoke BCI system is a testament to this, with carbon nanotube-coated electrodes at its core, enhancing the fidelity of neural interfacing through self-optimizing signal pathways.</p> <p>Our methodology is deeply rooted in bidirectional communication, leveraging AI to map cerebral signals onto interactive platforms, exemplified by our translation of neural impulses into gameplay dynamics. This iterative learning cycle commences at the cortical interface, progressing through a FreeEEG32 board, interfacing with our proprietary BrainFlow acquisition system, and culminating in our custom software. Here, our GUI provides an immersive analytical experience, inclusive of innovative visualizations such as the phase synchronization vortex.</p>"},{"location":"#system-configuration","title":"System Configuration","text":"<ul> <li>Brain Surface Communication: Neural activities are mapped via AI, translating into game movements and vice versa.</li> <li>Signal Transmission: The process begins with brain surface signals, read from our MEA, transmitted through a FreeEEG32 board, to BrainFlow for acquisition, then into our custom software for analysis.</li> <li>Neuromimetic Feedback: Neural signals are decoded into game actions, with game and in-game rat movement data (facilitating a self-loop learning concept) encoded back into neuromimetic signals. These signals are then fed back into the rat brain.</li> <li>Signal Processing: The 32 signals are sent to two 16 port usb hubs, connected to modified usb-audio converters, followed by resistors for voltage division to match ECoG voltage levels.</li> </ul>"},{"location":"#microelectrode-array-mea-specifications","title":"Microelectrode Array (MEA) Specifications","text":""},{"location":"#electrode-specifications","title":"Electrode Specifications","text":"<ul> <li>Type: 64 electrodes (32 input/recording, 32 output/stimulation).</li> <li>Wire Gauge: 30 AWG (254.6 micrometers diameter).</li> <li>Array Area: 3 cm\u00b2 total coverage.</li> <li>Spatial Resolution: 400-500 micrometers.</li> <li>Temporal Resolution: 1000 - 2000 Hz.</li> </ul>"},{"location":"#encasement-and-design","title":"Encasement and Design","text":"<ul> <li>Material: Medical-grade silicone for flexibility and biocompatibility.</li> <li>Thickness: 0.1 mm, accommodating brain tissue growth.</li> <li>Shape: Two connected trapezoids for conforming to brain curvature.</li> <li>Wiring: Twisted pair configuration for each electrode, reducing interference.</li> </ul>"},{"location":"#papers","title":"Papers","text":"<ul> <li>Phase 1: Software Development and Prospective Implantation of Microelectrode Arrays and Human Cortical Organoids into Rat Brains</li> </ul>"},{"location":"#rat-and-computer-learning","title":"Rat and Computer Learning","text":"<p>The system we've developed intricately blends advanced software automation with a nuanced understanding of rat behavior and neuroscience. Central to this system is the dual approach of reward and deterrent signaling, tailored specifically for the rat's unique sensory and cognitive processing.</p> <ul> <li> <p>Reward Mechanism: At the heart of positive reinforcement, our automated fluidics system is programmed to deliver a carefully formulated reward solution to the rat. This concoction, a precise blend of sucrose, sodium chloride, nicotine, and caffeine, is designed to stimulate the rat's reward centers, promoting engagement and positive response patterns. This aspect of the system is critical for encouraging the desired behaviors in the rat through natural, positive stimuli.</p> </li> <li> <p>Deterrent Signaling: Complementing the reward system is the deterrent mechanism, which employs audio signals beyond human auditory perception to subtly influence the rat's behavior. These human-inaudible distress sounds are calibrated to create a mild sense of unease or alertness in the rat, without causing undue stress or harm. This auditory deterrent is a key component in shaping the rat's behavior, helping to guide it away from undesirable actions or responses.</p> </li> <li> <p>AI-Driven Supervised Learning Framework: The convergence of these two systems is overseen and optimized by our sophisticated AI software. This AI component initiates the process through a phase of supervised learning, wherein incoming neural signals and corresponding actions are meticulously analyzed. The system then generates metadata-rich outgoing signals, which are fine-tuned to enhance the learning and adaptation process. This initial phase of supervised learning is crucial for establishing a robust foundation for the system's AI to learn, adapt, and evolve in response to the rat's neural patterns and behaviors.</p> </li> </ul> <p>In essence, our system represents a harmonious fusion of biotechnology and artificial intelligence, designed to explore and expand the boundaries of neuroscientific research and animal behavior understanding. This dynamic, responsive system is poised to offer unprecedented insights into neural processing, learning mechanisms, and the complex interplay between biological entities and computational intelligence.</p>"},{"location":"#doom-system","title":"DOOM system","text":"<p>In our system, we will leverage the combined capabilities of VizDoom and Gymnasium to access and utilize comprehensive game state information for effective decision-making and analysis. VizDoom will serve as our primary interface for interacting with the Doom game engine, providing us with rich access to various game state data such as player status, enemy positions, level layouts, weapon information, and observation spaces. Through Gymnasium, we will create custom gym environments tailored to our specific scenarios and objectives, allowing us to seamlessly integrate VizDoom's functionalities into our reinforcement learning pipelines. By harnessing the power of VizDoom and Gymnasium together, we aim to develop robust AI agents capable of understanding and navigating complex game environments, adapting their strategies based on real-time game state observations, and ultimately achieving specified objectives within the Doom universe.</p>"},{"location":"#subject-health-and-wellbeing","title":"Subject Health and Wellbeing","text":"<p>Central to our research ethos is the holistic well-being of the rats involved in our study. Recognizing the importance of social structures in the health and well-being of these animals, all rats are housed together in a communal environment. This approach not only supports their social health but also fosters a more natural living condition, crucial for their overall welfare.</p> <p>Nutrition is another cornerstone of our care regimen. The diet for these rats is meticulously planned and includes a rich variety of superfruits and fish oil supplements. This diet is designed to ensure optimal health, providing essential nutrients and antioxidants that support their cognitive and physical well-being.</p> <p>Furthermore, our commitment extends beyond the confines of the laboratory. We ensure that all rats exiting our wetlab are in robust health. Their release is carefully orchestrated, with a focus on their long-term welfare. They are released responsibly, in groups, to support their social nature and ease their transition back into a natural habitat. This practice underscores our dedication to ethical research and the humane treatment of all animals involved in our studies.</p> <p>We invite researchers to join us in this groundbreaking journey, to collaborate and contribute to the evolution of synthetic biological intelligence. Engage with us, and let\u2019s shape the future of brain-computer interfaces together.</p>"},{"location":"#key-features","title":"\ud83d\ude80 Key Features:","text":"<ul> <li>Tailored BCI &amp; MEA: Designed specifically for rat brains, enhancing neural connectivity and signal precision.</li> <li>Carbon Nanotube Technology: Exploits the adaptive capabilities of rat brains and CNTs for superior signal quality.</li> <li>Neural-Computational Language: Developing a novel symbolic language to streamline brain-computer communication, especially in gaming contexts.</li> </ul>"},{"location":"#collaborative-milestones","title":"\ud83e\udd1d Collaborative Milestones:","text":"<ul> <li>University of Michigan: Advancing optical stimulation in \"DishBrain\" experiment replicas.</li> <li>FinalSpark: Delving into human cortical spheroid learning mechanisms.</li> <li>University of Reading: Innovative use of bacteria in neural networks.</li> <li>City, University of London: Systems and states, including harmonics in TES EEG data.</li> </ul>"},{"location":"#inviting-collaboration","title":"\ud83d\udca1 Inviting Collaboration","text":"<p>We're reaching out to like-minded researchers and innovators to join us on this journey. Your expertise in BCI could be the catalyst for unprecedented breakthroughs. Let's explore the synergy between our visions and set new benchmarks in BCI technology.</p>"},{"location":"#join-us","title":"\ud83d\udce2 Join Us:","text":"<ul> <li>Discord: Connect with us on Discord and become part of a vibrant community shaping the future.</li> </ul>"},{"location":"#connect","title":"\ud83e\udd1d Connect","text":"<p>We're more than a project; we're a movement. Let's make history together. Get in touch!</p>"},{"location":"#license","title":"\ud83d\udcc4 License","text":"<p>This project is licensed under the Creative Commons Attribution-ShareAlike 4.0 International License.</p>"},{"location":"#related-projects","title":"\ud83e\uddec Related Projects","text":"<ul> <li>Human Cortical Organoid Signal Analysis: Signal analysis and prediction of brain signals, adaptable for various signal types. PyPI libraries available from our experiments.</li> <li>EEG Prediction with Chaos Theory: Leveraging chaos theory and a CNN Kuramoto transformer RNN for signal prediction. Includes PyPI library implementations.</li> <li>Bacteria Neural Network (Upcoming): An innovative approach using bacteria as functional components of a neural network. Collaboration between Synthetic Intelligence Labs and Complex Living Machines Lab Dr. Yoshikatsu Hayashi</li> </ul>"},{"location":"#contact","title":"\ud83d\udce9 Contact","text":"<p>For collaborations, press inquiries, or questions: - Email: soul.syrup@yandex.com or soul.syrupp@gmail.com - Discord: soul_syrup</p>"},{"location":"#library-testing-invitation","title":"\ud83d\udcda Library Testing Invitation","text":"<p>We invite you to test our PyPI library for human brain cortical organoid/spheroid, EEG, ECoG, and other signal analyses: - Neural Signal Analysis Library from Synthetic Intelligence Labs.</p> <p>Human-Brain-Rat by Synthetic Intelligence Labs is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License.Based on a work at Synthetic Intelligence Labs.Permissions beyond the scope of this license may be available at Synthetic Intelligence Labs.</p>"},{"location":"Mathetmatical%20Tools/","title":"Mathematical Tools","text":""},{"location":"Mathetmatical%20Tools/#detect-peaks","title":"Detect Peaks:","text":"\\[ \\begin{align*} \\text{Median Height} &amp;= \\text{median}(\\text{flattened\\_signals}) \\\\ \\text{Standard Deviation of Height} &amp;= \\text{std}(\\text{flattened\\_signals}) \\\\ \\text{Height Threshold} &amp;= \\text{Median Height} + \\text{Standard Deviation of Height} \\\\ \\text{Peak Distance} &amp;= \\text{len}(\\text{flattened\\_signals}) \\times 0.05 \\\\ \\text{Prominence Threshold} &amp;= \\text{Standard Deviation of Height} \\times 0.5 \\\\ \\text{Peak Count} &amp;= \\text{len}(\\text{peaks}) \\\\ \\text{Average Peak Height} &amp;= \\text{mean}(\\text{properties}[\"peak\\_heights\"]) \\\\ \\text{Average Distance Between Peaks} &amp;= \\text{mean}(\\text{np.diff}(\\text{peaks})) \\\\ \\text{Average Prominence of Peaks} &amp;= \\text{mean}(\\text{properties}[\"prominences\"]) \\end{align*} \\]"},{"location":"Mathetmatical%20Tools/#calculate-variance-and-standard-deviation","title":"Calculate Variance and Standard Deviation:","text":"\\[ \\begin{align*} \\text{Variance} &amp;= \\text{var}(\\text{signals}, \\text{axis}=1) \\\\ \\text{Standard Deviation} &amp;= \\text{std}(\\text{signals}, \\text{axis}=1) \\end{align*} \\]"},{"location":"Mathetmatical%20Tools/#calculate-rms","title":"Calculate RMS:","text":"\\[ \\text{RMS} = \\sqrt{\\text{mean}(\\text{signals}^2, \\text{axis}=1)} \\] <p>Where, \\begin{align} \\text{RMS} &amp;= \\text{Root Mean Square} \\ \\text{signals} &amp;= \\text{Array containing the input signals} \\ \\text{axis} &amp;= \\text{Axis along which the mean is computed, typically axis=1 for row-wise mean} \\end{align}</p>"},{"location":"Mathetmatical%20Tools/#frequency-bands","title":"Frequency Bands:","text":"\\[ \\begin{align*} \\text{Band Features}[i, j] &amp;= \\text{mean}(\\text{psd}[\\text{idx}]) \\quad \\text{if} \\quad \\text{np.any}(\\text{idx}) \\\\ &amp; \\quad \\quad \\quad \\text{else} \\quad 0.0 \\end{align*} \\] <p>Where, \\begin{align} \\text{Band Features}[i, j] &amp;= \\text{Mean power spectral density (PSD) in band } (i, j) \\ \\text{psd} &amp;= \\text{Power Spectral Density} \\ \\text{idx} &amp;= \\text{Indices of frequencies within band } (i, j) \\ \\text{np.any}(\\text{idx}) &amp;= \\text{Check if any indices are present in the band} \\ \\end{align}</p>"},{"location":"Mathetmatical%20Tools/#calculate-spectral-entropy","title":"Calculate Spectral Entropy:","text":"\\[ \\text{Spectral Entropy} = -\\sum_{i=1}^{n} p_i \\log_2(p_i) \\] <p>Where, \\begin{align} \\text{Spectral Entropy} &amp;= \\text{Entropy of the power spectral density (PSD)} \\ p_i &amp;= \\text{Normalized power in frequency bin } i \\ n &amp;= \\text{Number of frequency bins} \\end{align}</p>"},{"location":"Mathetmatical%20Tools/#spectral-centroids","title":"Spectral Centroids:","text":"\\[ \\text{Spectral Centroid} = \\frac{\\sum_{i=1}^{N} f_i \\cdot |X(i)|}{\\sum_{i=1}^{N} |X(i)|} \\] <p>Where, \\begin{align} \\text{Spectral Centroid} &amp;= \\text{Average frequency weighted by the magnitude spectrum} \\ f_i &amp;= \\text{Frequency of bin } i \\ X(i) &amp;= \\text{Magnitude of the Fourier transform at bin } i \\ N &amp;= \\text{Number of frequency bins} \\end{align}</p>"},{"location":"Mathetmatical%20Tools/#spectral-edge-density","title":"Spectral Edge Density:","text":"\\[ \\text{Spectral Edge Density} = \\text{Frequency}\\left[\\text{argmax}\\left(\\text{cumulative\\_sum} \\geq \\text{threshold}\\right)\\right] \\] <p>Where, \\begin{align} \\text{cumulative_sum} &amp;= \\text{Cumulative Sum of Power Spectral Density (PSD)} \\ \\text{threshold} &amp;= \\text{User-defined threshold} \\end{align}</p>"},{"location":"Python%20Utilities/","title":"Python Utilities","text":"<p>Our system mainly uses Python, thanks to its readability and wide range of packages in the field of data science, embedded and communication.</p> <p>Our project implements some utilities that makes the workflow simple and efficient. In this page you will get to know about it each utility.</p> <p>Note</p> <p>We are planning to publish these utilities as a python package to make it easy to develop the main dashboard. Once, all the code seems stable, it will be released as a package on GitHub. However, the documentation for that package remain the same.</p>"},{"location":"Python%20Utilities/#constants","title":"Constants","text":"<p>All the constant values are defined in the <code>constants.py</code>, it also contains some data structures. You can import these constants and use the values. It helps in maintaining code quality and prevents repetition.</p>"},{"location":"Python%20Utilities/#action","title":"Action","text":"<p>These are defined actions that are used in mainly used with VizDoom game.</p> Name Value Type MOVE_FORWARD MOVE_FORWARD str MOVE_BACKWARD MOVE_BACKWARD str TURN_LEFT TURN_LEFT str TURN RIGHT TURN RIGHT str USE USE str ATTACK ATTACK str <p>This class also has a classmethod to_dict(). This method returns this constant data structure as a dictionary, this allows flexibility to system where it is being used.</p> <p>Example usage: <pre><code>from constants import Action\n\nactions = Action()\nprint(actions.MOVE_FORWARD)\nprint(actions.to_dict())\n</code></pre></p> <p>You might think that why we would just define constants and create a classmethod to convert it to dictionary. Well, our system used these constants very often and at some point they were also required as a dictionary.</p>"},{"location":"Python%20Utilities/#actionmap","title":"ActionMap","text":"<p>When we decode features into <code>Actions</code> i.e move forward, backward or turn left or right etc. The actions are returned with some properties. This ActionMap class holds the same properties.</p> Name Value Type rms (Actions.MOVE_FORWARD, 3.96e-07) tuple variance (Actions.TURN_LEFT, 1.074e-26) tuple spectral_entropy (Actions.USE, 0.7) tuple peak_counts (Actions.ATTACK, 3) tuple higuchi_fractal_dimension (Actions.TURN_RIGHT, 1.35e-15) tuple zero_crossing_rate (Actions.MOVE_FORWARD, 0.1) tuple delta_band_power (Actions.MOVE_FORWARD, 0.5) tuple theta_band_power (Actions.MOVE_FORWARD, 0.5) tuple alpha_band_power (Actions.MOVE_FORWARD, 0.5) tuple beta_band_power (Actions.MOVE_FORWARD, 0.5) tuple peak_heights (Actions.MOVE_FORWARD, 0.5) tuple std_dev (Actions.MOVE_FORWARD, 7.5e-14) tuple centroids (Actions.MOVE_FORWARD, 0.5) tuple spectral_edge_density (Actions.MOVE_FORWARD, 0.5) tuple evolution_rate (Actions.MOVE_FORWARD, 0.5) tuple <p>You can learn about the terms used in this project from the page <code>Frequent Terms</code></p> <p>This data structure contains all data to be tuple, this class also has a <code>to_dict()</code> method wich converts they keys and the values set by the user to a dictionary.</p> <p>Example Usage: <pre><code>from constants import ActionMap\n\naction_map = ActionMap()\nactions_default = action_map.to_dict()  # Action map with default values\nprint(action_default)\n</code></pre> Output: <pre><code>{'rms': ('MOVE_FORWARD', 3.96e-07), 'variance': ('TURN_LEFT', 1.074e-26), 'spectral_entropy': ('USE', 0.7), 'peak_counts': ('ATTACK', 3), 'higuchi_fractal_dimension': ('TURN_RIGHT', 1.35e-15), 'zero_crossing_rate': ('MOVE_FORWARD', 0.1), 'delta_band_power': ('MOVE_FORWARD', 0.5), 'theta_band_power': ('MOVE_FORWARD', 0.5), 'alpha_band_power': ('MOVE_FORWARD', 0.5), 'beta_band_power': ('MOVE_FORWARD', 0.5), 'peak_heights': ('MOVE_FORWARD', 0.5), 'std_dev': ('MOVE_FORWARD', 7.5e-14), 'centroids': ('MOVE_FORWARD', 0.5), 'spectral_edge_density': ('MOVE_FORWARD', 0.5), 'evolution_rate': ('MOVE_FORWARD', 0.5)}\n</code></pre></p>"},{"location":"Python%20Utilities/#analyzesignalsresult","title":"AnalyzeSignalsResult","text":"<p>The signals received from MEAs are analysed to understand the nature of incoming data and the data we will be working further with. Many mathematical formulas are used to determine the features of signals.</p> <p>You can find these mathematical formulas in <code>Mathematical Formulas</code> section. </p> Name Value Type peak_height - Any peak_counts - int variance - float std_dev - float rms - float band_features - Any delta_band_power - Any theta_band_power - Any alpha_band_power - Any beta_band_power - Any centroids - Any spectral_edge_densities - Any higuchi_fractal_dimension - Any zero_crossing_rate - Any evolution_rate - Any <p>This method also contains <code>to_dict()</code> method but it also contains a <code>to_python_float()</code> method. The <code>to_python_float()</code> convert numpy.float64 to a python float if there is any.</p>"},{"location":"Python%20Utilities/#data-manager","title":"Data Manager","text":"<p>The system involves transmitting and receiving data alot. Currently, we are using Paho MQTT for this purpose. The scripts in themselves need to send data from one to another. To facilitate this complex movement of data we implemented a <code>DataManager</code> class which handles these tasks seamlessly.</p> <p>It has the following features:</p> <ul> <li>Multi-threaded / Non-Blocking</li> <li>Transmit &amp; Receive Concurrently</li> <li>Flexible</li> <li>Easy to Setup</li> </ul> <p>Because we will be having a lot of data manager classes in different parts of the system it might become difficult to provide arguments to each class and changing them would be a time-consuming task. To overcome this issue, we have designed data manager to take a <code>profile</code> and a function as an argument. Profile is simply a <code>.ini</code> file containing the keys.</p> Name Default Value Type Description client_id None str A client name to be used as an identifier for the client topic_sub None str A topic to subscribe, let it be None if client is only for receiving messages topic_pub None str A topic to publish message on, let it be None if client is only for sending messages function None function: Any A function you want to execute when message is received"},{"location":"Python%20Utilities/#example-profile","title":"Example Profile","text":"<pre><code>[General]\nclient_id=SampleClient\ntopic_sub=SomeTopicA\ntopic_pub=SomeTopicB\n</code></pre> <p>Note</p> <p>Make sure that you put all the keys in the General section.</p>"},{"location":"Python%20Utilities/#constructing-client","title":"Constructing client","text":"<pre><code>from data_manager import DataManager\n\ndata_m = DataManager(\"$PATH_TO_INI_FILE\")  # Without processing function\ndata_m = DataManager(\"$PATH_TO_INI_FILE\", some_function)  # With a processing function\n</code></pre> <p>Note</p> <p>Make sure that you are running a local or cloud MQTT broker at the defined host and port else, this will raise a Connection Refused error.</p>"},{"location":"Python%20Utilities/#receiving-data","title":"Receiving data","text":"<p>For only recieving messages you need to specify <code>topic_sub</code> and leave <code>topic_pub</code> to None.</p> <pre><code>from data_manager import DataManager\n\ndata_m = DataManager(\"$PATH_TO_INI_FILE\", some_function) \ndata_m.listen()\n</code></pre> <p>Just 2 lines, yeah just 2 lines to start receiving messages. This starts the server loop on a new thread which prevents blocking main thread. You can also pass a function that you want to execute when you receive any data, this also helps you to utilise data that you will be receving. </p> <p>For example, lets say we will be receving a string on test_topic and to that we string we want to append foo and print it.</p> <pre><code>def foo(msg):\n    print(f\"{msg} foo\")\n\ndata_m = DataManager(\"$PATH_TO_INI_FILE\", foo) \ndata_m.listen()\n</code></pre> <p>Now this will print a string that will have foo in it. You can pass your own function but make sure you take the incoming message as the first argument of your custom function.</p>"},{"location":"Python%20Utilities/#sending-data","title":"Sending data","text":"<p>Sending data is simple, you need to specify <code>topic_pub</code> for the client. For such case you don't need to specify <code>processing_func</code>.</p> <pre><code>from data_manager import DataManager\n\ndata_m = DataManager(\"$PATH_TO_INI_FILE\", foo) \ndata_m.set_data(\"This is the message I want to send.\")\ndata_m.publish()\n</code></pre> <p>Note</p> <p>There are two function <code>publish</code> and <code>publish_data</code> both are different, you need to call <code>publish</code> function not <code>publish_data</code></p> <p>In this way you send data in just 3 lines. But, you need to be carefull while sending data. Firstly, you need to specify data through <code>set_data()</code> function, <code>self.data</code> is the property of DataManager class which is set by the user through this function. Then you need to call the function <code>publish(sleep_time: float)</code></p> <p>Data Manager also has a <code>publish_data()</code> function, but the function <code>publish()</code> executes publish_data() function on a new thread so that main thread is not blocked.</p>"},{"location":"Python%20Utilities/#sending-receving-data-concurrently","title":"Sending &amp; Receving Data Concurrently","text":"<p>We are not done yet, you can also receive and set data concurrently through same class. You just need to specify both <code>topic_sub</code> and <code>topic_pub</code></p> <pre><code>def foo(msg):\n    print(f\"{msg} foo\")\n\ndata_m = DataManager(\"$PATH_TO_INI_FILE\", foo) \ndata_m.listen()\n\ndata_m.set_data(\"I am sending this message\")\ndata_m.publish()\n\n# Your code ......\n# And it will not be blocked\n</code></pre>"},{"location":"Python%20Utilities/#logging-service","title":"Logging Service","text":"<p>Our system is wide and complex so it becomes really important to keep records of events being fired behind the scene. So, to save logs we implemented a <code>LoggingService</code> class that uses <code>DataManager</code> and listens for logging data on topic logs. This includes a <code>RotatingFileHandler</code> that means if the size of log file reaches the limit a new file will be created and data will be written to it. The limit set is 200 MB for each file.</p>"},{"location":"Python%20Utilities/#formats","title":"Formats","text":"<p>The format in which we want to save our logs is an important parameter, we have provided a class containing string of all formats available with python's built-in package <code>logging</code></p> <pre><code>class Formats:\n    BASIC_FMT = \"%(asctime)s %(levelname)s %(message)s\"\n    FUNC_FMT = \"%(asctime)s: %(levelname)s - %(funcName)s - %(message)s\"\n    LINE_NO_FMT = \"%(asctime)s: %(levelname)s -%(lineno)d - %(message)s\"\n</code></pre>"},{"location":"Python%20Utilities/#logging-data","title":"Logging data","text":"<p>To log data you need to send a dictionary converted into json as string on topic logs. The logger will automatically log the data whenever you send a json on the topic. Make sure to follow the given format for dictionary.</p> <pre><code>{\n    'level': \"LEVEL_INT\",\n    'msg': \"YOUR_MESSAGE_OR_EVENT\",\n    'funcName' : 'NAME_OF_THE_FUNCTION'  # put as 'NA' if you dont want to use it.\n    'lineno' : 'LINE_NUMBER' # put as 'NA' if you dont want to use it.\n}\n</code></pre> <p>The parameters <code>level</code>, <code>msg</code> are important and cannot be set NA.</p>"},{"location":"Python%20Utilities/#convert-to-database","title":"Convert to database","text":"<p>If you have a lot of logs then it might be difficul to read that through the file itself, to make analysing the logs easy we provide a function <code>convert_to_database()</code> which takes no argument and converts the log file into a sqlite3 database file. Also make sure to follow the given template for .db file. You can download the template.db file from here.</p>"},{"location":"System%20Design/","title":"System Design","text":"<p>This research involves complex software worflow. Therefore, it becomes essential to visualize the process. </p> <p></p> <ul> <li>Step 1: Raw EEG signals are fetched over 32 channels from the subject.</li> <li>Step 2: The recieved analog signals are then converted into digital signals.</li> <li>Step 3: In this step the digital signals are decoding into movements using features (e.g move forward or backward, turn left or right).</li> <li>Step 4: VizDoom has its own set of commands to perform defined action inside of the game environment. The movements are converted into VizDoom commands.</li> </ul> <p>At each step some mathematical formulas are used to process data, these formulas can be found in papers from <code>References</code> section.</p>"},{"location":"System%20Design/#tools","title":"Tools","text":"<p>Under application we provide main software and tools such as Signal Simulator &amp; Script Monitor. These tools can be found on GitHub Repo releases.</p> <p>Currently, we have two tools</p> <ul> <li> <p>Signal Simulator - The actual signals are generated through MEA that are implanted into the subjects brain. But for testing the system software we simulate signals using this tools. It mimics the FreeEEG board.</p> </li> <li> <p>Scripts Monitor - The data is being published on different Mqtt topics by scripts and some scripts simultaneously. While development it becomes messy to open multiple terminal windows and look at each of them one by one. This tools lets you see what's being published on topics continously.</p> </li> </ul> <p>We are now dropping the support of Scripts Monitor tool because it will be intergrated within the first version of Unified Software.</p>"},{"location":"Tools/Event%20Monitor/","title":"Event Monitor","text":"<p>Event monitor tools monitors the event. The signals sent on the topic SIGNALS are received by other scripts that extract features from it. These features are then translated into game commands that VizDoom can understand. With this tools you just need to start a local MQTT broker and then you can look on the events. This tool is helpful in keeping records for observation purposes.</p> <p> </p> <p>You need to enter the host and port of your MQTT broker, topics are already defined as constants in constanst.py file. After, setting them up just click <code>Start</code> button under <code>Settings</code> tab.</p> <p>You will now recieve the inputs for the game that are extracted from the signals. Also, you can export the data with timestamp by clicking <code>Export</code> button under <code>Settings</code> tab.</p> <p>Note</p> <p>You must create a file in which you want to write data the data. The tools does not create a new file.</p>"},{"location":"Tools/Signal%20Simulator/","title":"Signal Simulator","text":"<p>The actual signals are captured throug MEA implanted in the subject's brain. But for testing software, we use simulated signals. This Signal Simulator tool generates signals and publishes them over the same topic as that of actual data. These signals are then received by the data manager instances subscribed to the topic.</p> <p>Note</p> <p>Please refer to Topics section in System Design to see active topics.</p> <p></p> <p>The UI is simple but it has a lot of parameter to input by the user. To make this process more simpler you have to input the values once, then you <code>Save</code> &amp; <code>Load</code> your configurations.</p>"},{"location":"Tools/Signal%20Simulator/#progress","title":"Progress","text":"<ul> <li> Basic user interface</li> <li> Error handling</li> <li> Publish Messages</li> <li> Save &amp; Get values</li> <li> Stable Release</li> </ul>"},{"location":"Tools/Signal%20Simulator/#parameters-discription","title":"Parameters &amp; Discription","text":"Key Description <code>min_volt</code> 1 microvolt <code>max_volt</code> 8 microvolts <code>variability_factor</code> Direct mapping of player movement to variability factor, normalized to 0-1 <code>variance</code> Mapping door state to variance feature <code>std_dev</code> Mapping enemy type to standard deviation feature <code>rms_value</code> Player health state affects the RMS value feature <code>num_peaks</code> Number of peaks determined by exploring states <code>peak_height</code> Peak height influenced by level state <code>fractal_dimension</code> Action states influence the fractal dimension <code>window_size</code> Window size feature influenced by wall states <code>target_rate</code> Target rate is determined by the presence of any enemy type <code>min_freq</code> Minimum frequency affected by player movement <code>max_freq</code> Maximum frequency influenced by player health state <code>blend_factor</code> Static blend factor as a static state <code>global_sync_level</code> Global sync level determined by action state <code>pairwise_sync_level</code> Pairwise sync level affected by door state <code>sync_factor</code> Sync factor as a static value for simplicity <code>influence_factor</code> Influence factor derived from enemy type <code>max_influence</code> Maximum influence as a static maximum for the presence of any enemy <code>centroid_factor</code> Centroid factor and edge density factor as placeholders for sensory data encoding <code>edge_density_factor</code> Centroid factor and edge density factor as placeholders for sensory data encoding <code>complexity_factor</code> Example value for complexity factor in FFT <code>evolution_rate</code> Evolution rate as a static value for dynamic environmental changes <code>low_freq</code> Low frequency ranges influenced by exploring states <code>high_freq</code> High frequency ranges influenced by level states <code>causality_strength</code> Causality strength as a static value for interaction effects <code>num_imfs</code> Number of intrinsic mode functions (IMFs) as a static value for interaction effects <p>A dialog will open up asking for some more parameters. These parameters define signals.</p> <p></p> Key Description <code>num_signals</code> Number of signals you want to generate <code>bit_depth</code> <code>duration</code> <code>sampling_frequency</code> <p>After you provide all the inputs, it will generate the signals and send transformed signals to topic SIGNALS. Then it will plot these signals and write them to your current directory as image files.</p> <p></p>"},{"location":"Unified%20Software/For%20Developers/","title":"For Developers","text":"<p>Hello Developers, welcome to the start of our exciting journey together. We're embarking on an adventure to develop the Unified Software, a project with the potential to revolutionize Bio-Computing. This software is the heart \u2764\ufe0f of our research project.</p> <p>Let's dive in and start discussing how we can bring this vision to life!</p>"},{"location":"Unified%20Software/For%20Developers/#what-is-unified-software","title":"What is Unified Software ?","text":"<p>Unified software is a computer software being developed under this research project to control complete system which includes data analysis, hardware control, monitoring and conversion of neural signals and more. It will help researchers to develop Bio-Sillicn systems.</p> <p>This page answers frequent question that will pop-up in your heads when you will start developing this software. If your question is not answered here, feel free to reach us through GitHub or Discord</p>"},{"location":"Unified%20Software/For%20Developers/#how-to-get-started","title":"How to get started ?","text":"<p>Before getting started, it's important to ask \"What's required to get started?\" Below are the requirements to get started:</p> <ul> <li>\ud83d\udc68\u200d\ud83d\udcbb Turn on your super developer mode.</li> <li>\ud83c\udfa7 Your favorite music.</li> <li>\u270d\ufe0f Your code editor.</li> <li>\ud83d\udc0d Python installed.</li> <li>C++ installed.</li> <li>\u2615 Don't forget the energy drink of devs.</li> </ul> <p>Linux based operating systems are recommended. Now, let's talk about How to get started ?. We should first start by understanding the structure of the software.</p> <p>The software architecture is quite big and complicated so it's broken down into smaller peices. Throught the development it is high recommended to develop each peice independent of other i.e if one piece of software malfunctions then whole software should not crash. This will ensure reliability and stability.</p>"},{"location":"Unified%20Software/For%20Developers/#structure","title":"Structure","text":"<p>We will divide the structure into MUST TO HAVE, IMPORTANT TO HAVE and GOOD TO HAVE</p> <ul> <li><code>Must to have</code>: The features we must implement to devliver the root functionality, the High Priority features.</li> <li><code>Important to have</code>: The features that should implement basically features on Moderate priority features.</li> <li><code>Good to have</code>: The features with low priority i.e additional themes, animations etc.</li> </ul>"},{"location":"Unified%20Software/For%20Developers/#must-to-have","title":"Must To Have","text":"<ul> <li> <p>Update Tool: Checks for software updates including games and updates the software if they are available. This is important because we don't need our users to download a .zip file again and again for even small changes.</p> </li> <li> <p>Settings App: Through this app users can change settings of the software according to their needs. This is important not only for users but for our developers too because it will be a bit time-consuming to hard code configuration values.</p> </li> <li> <p>Logger Service: This is one of the most crucial part of any software because it's important to for every user and developer to know what going behind the scenes.</p> </li> <li> <p>Basic Dark Theme: We are using Qt Framework with C++ &amp; Python which provides us with a set of widgets with native style which may not look very pleasant to the user especially when using software for a long period of time. </p> </li> <li> <p>Data Manager (C++): The data manager tool is an important part of this whole system, it helps us to communicate between different peices. In this software we are utilising both Python &amp; C++ which cannot communicate directly.</p> </li> <li> <p>Thread Management Service: We will be creating many threads during the run-time for different tasks, so it's important to keep a track of the thread working.</p> </li> <li> <p>Neural Signals Converter: This will convert the neural signals (Analog) to Digital so that we can process them. This will also convert digital singals back into analog signals so that the subject can process the signals.</p> </li> <li> <p>Game State Update Serivce: We will have different games that will be played by the subject which will be running in different window, we need to update the game state in the software so that the user is aware about what's going on.</p> </li> </ul>"},{"location":"Unified%20Software/For%20Developers/#important-to-have","title":"Important To Have","text":"<ul> <li> <p>Log Analysis Tool: This will help users to find the most occuring errors and warnings and understand what went wrong or in what sequence things were executed.</p> </li> <li> <p>Session Manager: This will be help users save all their data generated while a session.</p> </li> </ul>"},{"location":"Unified%20Software/For%20Developers/#good-to-have","title":"Good To Have","text":"<ul> <li>Just some extra themes.</li> </ul>"},{"location":"Unified%20Software/For%20Developers/#creating-pull-requests","title":"Creating Pull Requests","text":"<p>You made any modification or you have better approach and want to bring to light, just make a pull request in the Unfied Software branch. Your pull request should include a clear description the following:</p> <ul> <li>Code</li> <li>What you are trying to acheive ?</li> <li>How is your better than the current one ?</li> </ul>"}]}